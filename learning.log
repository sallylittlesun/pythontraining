这个文件，主要用来记录一下写小例子过程中遇到的问题。

9.18
写d0004的时候，在网上看到好几种方法，有一个之前没有接触的模块，collections，常用的类型有:Counter,deque,defaultdict,OrderedDict,namedtuple。看用途Counter deque可能作用会大一点，Counter是用于计数的，计数后返回值是字典，key是元素，value是元素个数。deque主要是可以从两边对数据进行增加删除的操作。

还有用re模块进行findall正则匹配查找单词，暂时还没有仔细看。


9.20
d0005，有2个问题 一个是对目标目录的遍历，一个是对图像的处理。
目录遍历我用的是python自带的函数，感觉可能用shell命令会更快一点，现在写的循环数量大的时候会很慢。
图像处理，一开始想用Image模块的resize函数，但是这个函数不是按比例缩放的，不是很合适。


9.25
今天主要是学习熟悉了一下用python解析html，网上看可用的库比较多，选择了Beautiful Soup,文档https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/，安装方式：apt-get install Python-bs4，这个库的功能还是比较多的。
把html网址转化成源码，urllib2库，
page =urllib2.urlopen(url)
print page.read()
使用bs的时候，会出现报错UnicodeEncodeError: 'ascii' codec can't encode character u'\xf8' in position 7318: ordinal not in range(128)
因为python默认编码是ascii，所以在脚本开始把编码改成utf-8即可。

10.9
今天主要练习的是PIL模块的例子，注意新建图片时，图片大小设置先宽后高。
随机生成数字字母，可以用ascii码对应序号，再用chr()函数生成。


10.10
简单练习了一下敏感词的查找，网上有一些用python 进行敏感词查找的例子，DFA算法，这个没有怎么看懂，还要再研究一下，map函数跟lamba还需要练习一下。
http://blog.csdn.net/huangxiongbiao/article/category/2116035/2  这个是别人写的程序，可以参考学习。

10.16
敏感词替换，使用替换的时候会遇到编码问题导致的字数统计问题，提取敏感词的时候要decord成utf-8的格式，不然后面替换时会用ascaii码的字数替换，一次循环之后可能会出现新的组成敏感词，这个问题要考虑。形成新的字符串时注意，定义时要先把新字符串=输入字符，然后再替换，不然会一直只是最后一个敏感词的替换。


10.17
今天主要练习了一下python表格应用跟正则表达式的应用，re的应用还需要好好练习一下，http://www.cnblogs.com/huxi/archive/2010/07/04/1771073.html
python表格处理使用的是xlwt，这个要注意一下，在linux环境下，要加encoding=utf-8，否则中文会报错。
http://www.cnblogs.com/liez/p/5380925.html#3409968

10.18
今天还是练习了一下正则表达式的使用，并且尝试了一下更加精简的代码结构，注意：写入表格时先行后列，处理数据的时候要通过定义一个变量，循环来遍历表格。

10.19
表格和xml之间的转换，xlwt是写表格模块，xlrd是读表格模块。


10.26
今天写了一下表格和xml之间的转换，有几个问题，1：中文无法识别，报错Non-ASCII character '\xe5'  but no encoding declared，网上找的在文件开头重置编码格式的不起作用，之后我把encoding删除重新写了一遍可以了；2：读取出来的文件中文显示有问题，用python生成的表格读取数据都是unicode编码，所以数字和中文都需要再处理。列表和字典里的中文直接打印出来都会变成utf-8格式。可以通过逐个打印，或者字典使用print json.dumps(dict, ensure_ascii=False, encoding='UTF-8'),但是写入xml文件的中文还是utf-8格式。
14-16对固定格式文本的处理，可以用eval()函数，这个会简单方便很多。用eval()获取的数据格式跟之前用正则式匹配的不一样，数字变成了float型，但是中文显示还是有问题，不知道是不是因为linux系统的原因。而且有一个问题是，用了eval()之后，数据顺序会有变化。

